{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **WORD2VEC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import logging\n",
    "\n",
    "# Enable logging for Gensim\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Function to read and preprocess text file\n",
    "def read_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Tokenize the line into words\n",
    "            yield simple_preprocess(line)\n",
    "\n",
    "# Path to your text file\n",
    "file_path = 'finance_dataset.txt'\n",
    "\n",
    "# Load and preprocess the text data\n",
    "corpus = list(read_corpus(file_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whether',\n",
       " 'you',\n",
       " 're',\n",
       " 'first',\n",
       " 'time',\n",
       " 'investor',\n",
       " 'or',\n",
       " 'have',\n",
       " 'been',\n",
       " 'investing',\n",
       " 'for',\n",
       " 'many',\n",
       " 'years',\n",
       " 'there',\n",
       " 'are',\n",
       " 'some',\n",
       " 'basic',\n",
       " 'questions',\n",
       " 'you',\n",
       " 'should',\n",
       " 'always',\n",
       " 'ask',\n",
       " 'before',\n",
       " 'you',\n",
       " 'commit',\n",
       " 'your',\n",
       " 'hard',\n",
       " 'earned',\n",
       " 'money',\n",
       " 'to',\n",
       " 'an',\n",
       " 'investment']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMOD architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 20:35:12,335 : INFO : collecting all words and their counts\n",
      "2024-07-04 20:35:12,336 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-07-04 20:35:12,344 : INFO : collected 2800 word types from a corpus of 41775 raw words and 2686 sentences\n",
      "2024-07-04 20:35:12,345 : INFO : Creating a fresh vocabulary\n",
      "2024-07-04 20:35:12,348 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1854 unique words (66.21% of original 2800, drops 946)', 'datetime': '2024-07-04T20:35:12.348218', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2024-07-04 20:35:12,348 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 40829 word corpus (97.74% of original 41775, drops 946)', 'datetime': '2024-07-04T20:35:12.348576', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2024-07-04 20:35:12,354 : INFO : deleting the raw counts dictionary of 2800 items\n",
      "2024-07-04 20:35:12,356 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2024-07-04 20:35:12,356 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 29685.51231408117 word corpus (72.7%% of prior 40829)', 'datetime': '2024-07-04T20:35:12.356506', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2024-07-04 20:35:12,373 : INFO : estimated required memory for 1854 words and 100 dimensions: 2410200 bytes\n",
      "2024-07-04 20:35:12,373 : INFO : resetting layer weights\n",
      "2024-07-04 20:35:12,375 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-07-04T20:35:12.375290', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}\n",
      "2024-07-04 20:35:12,377 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 1854 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-07-04T20:35:12.377866', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2024-07-04 20:35:12,408 : INFO : EPOCH 0: training on 41775 raw words (29710 effective words) took 0.0s, 1400123 effective words/s\n",
      "2024-07-04 20:35:12,428 : INFO : EPOCH 1: training on 41775 raw words (29747 effective words) took 0.0s, 1826652 effective words/s\n",
      "2024-07-04 20:35:12,454 : INFO : EPOCH 2: training on 41775 raw words (29628 effective words) took 0.0s, 1302238 effective words/s\n",
      "2024-07-04 20:35:12,474 : INFO : EPOCH 3: training on 41775 raw words (29609 effective words) took 0.0s, 1801182 effective words/s\n",
      "2024-07-04 20:35:12,499 : INFO : EPOCH 4: training on 41775 raw words (29625 effective words) took 0.0s, 1582832 effective words/s\n",
      "2024-07-04 20:35:12,499 : INFO : Word2Vec lifecycle event {'msg': 'training on 208875 raw words (148319 effective words) took 0.1s, 1229913 effective words/s', 'datetime': '2024-07-04T20:35:12.499697', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2024-07-04 20:35:12,500 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1854, vector_size=100, alpha=0.025>', 'datetime': '2024-07-04T20:35:12.500116', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Word2Vec model\n",
    "cmod_model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=2, workers=8)\n",
    "\n",
    "# Save the model\n",
    "# model.save(\"word2vec.model\")\n",
    "\n",
    "# Load the model (if you want to continue training or use it later)\n",
    "# model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# Optional: Fine-tune an existing pre-trained model\n",
    "# model = Word2Vec.load('pretrained_model_path')\n",
    "# model.build_vocab(corpus, update=True)\n",
    "# model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('market', 0.9996460676193237), ('one', 0.9995118975639343), ('bonds', 0.9994921684265137), ('stock', 0.999480128288269), ('prices', 0.9994395971298218), ('higher', 0.9994344115257263), ('their', 0.9994331002235413), ('by', 0.9994164705276489), ('securities', 0.9994156956672668), ('than', 0.9994068741798401)]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "print(cmod_model.wv.most_similar('money'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('more', 0.99833744764328),\n",
       " ('so', 0.9982842206954956),\n",
       " ('these', 0.9982642531394958),\n",
       " ('their', 0.9982610940933228),\n",
       " ('would', 0.99825519323349),\n",
       " ('if', 0.9982499480247498),\n",
       " ('generally', 0.9982090592384338),\n",
       " ('within', 0.9981884956359863),\n",
       " ('will', 0.9981809854507446),\n",
       " ('class', 0.9981784820556641)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmod_model.wv.most_similar('fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip gram architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 20:35:37,390 : INFO : collecting all words and their counts\n",
      "2024-07-04 20:35:37,391 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-07-04 20:35:37,396 : INFO : collected 2800 word types from a corpus of 41775 raw words and 2686 sentences\n",
      "2024-07-04 20:35:37,398 : INFO : Creating a fresh vocabulary\n",
      "2024-07-04 20:35:37,405 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 2800 unique words (100.00% of original 2800, drops 0)', 'datetime': '2024-07-04T20:35:37.405253', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2024-07-04 20:35:37,405 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 41775 word corpus (100.00% of original 41775, drops 0)', 'datetime': '2024-07-04T20:35:37.405944', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2024-07-04 20:35:37,417 : INFO : deleting the raw counts dictionary of 2800 items\n",
      "2024-07-04 20:35:37,420 : INFO : sample=0.001 downsamples 65 most-common words\n",
      "2024-07-04 20:35:37,421 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30772.16889351392 word corpus (73.7%% of prior 41775)', 'datetime': '2024-07-04T20:35:37.421794', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2024-07-04 20:35:37,442 : INFO : estimated required memory for 2800 words and 100 dimensions: 3640000 bytes\n",
      "2024-07-04 20:35:37,445 : INFO : resetting layer weights\n",
      "2024-07-04 20:35:37,448 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-07-04T20:35:37.447960', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}\n",
      "2024-07-04 20:35:37,448 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 2800 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-07-04T20:35:37.448662', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2024-07-04 20:35:37,522 : INFO : EPOCH 0: training on 41775 raw words (30879 effective words) took 0.1s, 433355 effective words/s\n",
      "2024-07-04 20:35:37,588 : INFO : EPOCH 1: training on 41775 raw words (30863 effective words) took 0.1s, 502584 effective words/s\n",
      "2024-07-04 20:35:37,647 : INFO : EPOCH 2: training on 41775 raw words (30723 effective words) took 0.1s, 533649 effective words/s\n",
      "2024-07-04 20:35:37,712 : INFO : EPOCH 3: training on 41775 raw words (30824 effective words) took 0.1s, 499141 effective words/s\n",
      "2024-07-04 20:35:37,781 : INFO : EPOCH 4: training on 41775 raw words (30777 effective words) took 0.1s, 469410 effective words/s\n",
      "2024-07-04 20:35:37,782 : INFO : Word2Vec lifecycle event {'msg': 'training on 208875 raw words (154066 effective words) took 0.3s, 462304 effective words/s', 'datetime': '2024-07-04T20:35:37.782211', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2024-07-04 20:35:37,782 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=2800, vector_size=100, alpha=0.025>', 'datetime': '2024-07-04T20:35:37.782760', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Create Skip Gram model\n",
    "skip_gram_model = gensim.models.Word2Vec(corpus, min_count=1, vector_size=100,\n",
    "                                window=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('market', 0.9646204113960266),\n",
       " ('stocks', 0.9560030698776245),\n",
       " ('lower', 0.9381133913993835),\n",
       " ('low', 0.9293083548545837),\n",
       " ('stock', 0.9273928999900818),\n",
       " ('prices', 0.9264268279075623),\n",
       " ('many', 0.9257183074951172),\n",
       " ('offer', 0.92472904920578),\n",
       " ('hold', 0.9210673570632935),\n",
       " ('government', 0.9208395481109619)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.wv.most_similar('money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('forms', 0.9980872273445129),\n",
       " ('ks', 0.9980408549308777),\n",
       " ('providing', 0.9980121850967407),\n",
       " ('format', 0.9979974627494812),\n",
       " ('regulators', 0.997897744178772),\n",
       " ('gathering', 0.9978830814361572),\n",
       " ('communications', 0.9978770613670349),\n",
       " ('calendar', 0.9978488683700562),\n",
       " ('nfa', 0.9978326559066772),\n",
       " ('doesn', 0.9978095889091492)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.wv.most_similar('fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('costs', 0.9296042919158936),\n",
       " ('exchange', 0.9281546473503113),\n",
       " ('other', 0.9243658185005188),\n",
       " ('these', 0.9242442846298218),\n",
       " ('associated', 0.9214975237846375),\n",
       " ('are', 0.9205516576766968),\n",
       " ('marketing', 0.9147732257843018),\n",
       " ('etfs', 0.9144077897071838),\n",
       " ('transaction', 0.9140551686286926),\n",
       " ('cover', 0.9133368134498596)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.wv.most_similar('mutual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03186354,  0.32417858,  0.14346322, -0.15774702,  0.09189676,\n",
       "       -0.47482914, -0.17094539,  0.6206782 , -0.20372252, -0.25861514,\n",
       "        0.02837114, -0.15952699,  0.0524365 ,  0.11811804,  0.08754283,\n",
       "       -0.1337938 , -0.25736433, -0.08980535, -0.21476537, -0.30813828,\n",
       "        0.06541857,  0.06429306,  0.00417759, -0.27984196, -0.06468371,\n",
       "        0.22596422, -0.06331495, -0.19226734, -0.09995241, -0.04522065,\n",
       "        0.19653024, -0.05441574, -0.04164902, -0.2122644 , -0.0101136 ,\n",
       "        0.32226843, -0.18886194, -0.05141347, -0.05913561, -0.4526042 ,\n",
       "        0.11383466, -0.2763586 , -0.11798654, -0.11933243,  0.31945884,\n",
       "       -0.05703748, -0.22343343, -0.05948214,  0.27238002,  0.15054794,\n",
       "        0.13620704, -0.09449068, -0.21174619, -0.05979099,  0.0951125 ,\n",
       "        0.23590812,  0.01026949, -0.20144197,  0.19672489, -0.11833731,\n",
       "       -0.07434704,  0.04828395,  0.1223577 ,  0.02831285, -0.26652297,\n",
       "        0.3052809 ,  0.22848807,  0.20004109, -0.4478334 ,  0.45277134,\n",
       "       -0.16868995,  0.11942324,  0.31468907, -0.18496543,  0.08274203,\n",
       "        0.10680246, -0.12020005, -0.19924037, -0.22902547, -0.02475074,\n",
       "       -0.2619346 , -0.06673581, -0.41471288,  0.35588452, -0.06753149,\n",
       "       -0.04399554, -0.14889492,  0.11517587,  0.37900937,  0.1156803 ,\n",
       "        0.20738359,  0.2451786 ,  0.24588054,  0.22215085,  0.35408327,\n",
       "        0.27954328, -0.18767533,  0.01115715, -0.27711207, -0.28510737],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1=skip_gram_model.wv.get_vector(\"bonds\")\n",
    "vect1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.78620045e-02,  3.58871520e-01, -4.38098535e-02, -1.64416388e-01,\n",
       "        2.66807992e-03, -4.34183747e-01, -2.19288631e-06,  6.10115588e-01,\n",
       "       -1.92931235e-01, -2.80438960e-01,  2.03854982e-02, -1.10006459e-01,\n",
       "       -5.94976023e-02,  1.18451245e-01,  1.88981280e-01, -9.04520974e-03,\n",
       "        2.91454978e-02, -1.66115195e-01, -2.24505931e-01, -3.83823991e-01,\n",
       "       -4.94315177e-02,  6.48309384e-03,  8.59050378e-02, -3.12959641e-01,\n",
       "       -4.24083360e-02,  1.85719520e-01, -1.01716600e-01, -2.09054202e-01,\n",
       "       -6.13547340e-02,  2.05489760e-03,  1.94964126e-01, -1.05095461e-01,\n",
       "        3.70531790e-02, -3.11945409e-01, -1.14812352e-01,  3.24904233e-01,\n",
       "       -1.94945857e-01, -2.07500886e-02, -5.87579096e-03, -3.74134809e-01,\n",
       "        1.50425091e-01, -3.37718546e-01, -6.83552995e-02, -1.68188155e-01,\n",
       "        3.40573192e-01, -4.92074974e-02, -4.81893234e-02, -8.20087641e-02,\n",
       "        3.39681432e-02,  1.42702147e-01,  2.15705261e-01, -7.68500492e-02,\n",
       "       -6.58555180e-02, -5.39472625e-02, -1.19122572e-01,  5.64298145e-02,\n",
       "        1.00561701e-01, -2.00074852e-01,  4.10568938e-02, -1.85225008e-03,\n",
       "        5.29709160e-02, -1.61317259e-01,  3.05264980e-01, -1.42111648e-02,\n",
       "       -4.59233709e-02,  3.27099472e-01,  2.19119936e-01,  2.52949506e-01,\n",
       "       -4.17689353e-01,  4.36347395e-01, -1.53281465e-01,  1.18067458e-01,\n",
       "        1.10791311e-01, -4.47038785e-02,  2.36679867e-01,  2.58235745e-02,\n",
       "       -1.31737962e-01, -1.03481106e-01, -1.05555028e-01, -2.38091741e-02,\n",
       "       -2.45928600e-01,  3.06278300e-02, -2.87313223e-01,  3.01000714e-01,\n",
       "       -7.81264454e-02, -1.37108520e-01,  1.67565763e-01,  4.08563577e-02,\n",
       "        2.34907821e-01,  1.64603487e-01,  2.08802164e-01,  1.00793853e-01,\n",
       "        8.50603282e-02,  1.84224606e-01,  4.08091336e-01,  2.05272362e-01,\n",
       "       -6.59764931e-02, -2.95236893e-02, -2.34937772e-01, -1.28395006e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2=skip_gram_model.wv.get_vector(\"money\")\n",
    "vect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87678164], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.wv.cosine_similarities(vector_1=vect1 , vectors_all=[vect2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
